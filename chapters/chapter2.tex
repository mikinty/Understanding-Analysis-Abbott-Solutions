\section{Chapter 2}

%% 2.2 %%

\setcounter{subsection}{2}

\bx{
% possibly only prove first one since the proofs are basically the same.
\ea{
	\item Let $\epsilon > 0$ be arbitrary. Then choose $n\in \mathbb{N}$ such that $n > \frac{1}{\sqrt{6\epsilon}}$. Then 
	\begin{align*}
	\abs{\frac{1}{6n^2 + 1}} &< \abs{\frac{1}{6\frac{1}{6\epsilon} + 1}} \\
	&< \abs{\frac{1}{\frac{1}{\epsilon} + 1}} \\
	&< \frac{\epsilon}{\epsilon + 1} \\
	&< \epsilon
	\end{align*}
	as desired.
	
	\item Choose $n > \frac{13}{2\epsilon} - \frac{5}{2}$
	\item Choose $n > \frac{4}{\epsilon^2} - 3$
}
}

\bx{
Consider the sequence
\begin{equation}
x_n = (-1)^n, n \geq 1.
\end{equation}
Then for $\epsilon > 2$, it is true that $\abs{x_n - 0} < 2, \forall n \geq 1$.

The \textit{vercongent} definition describes a sequence that can be finitely bounded past some $n$.
}

\bx{
\ea{
	\item We have to find one school with a student shorter than 7 feet.
	\item We would have to find a college with a grade lower than B.
	\item We just have to check every college for a student who is shorter than 6 feet.
}
}

\bx{
For $\epsilon > \frac{1}{2}$, we can find a suitable $N$, since we can claim the sequence ``converges'' to $\frac{1}{2}$. For $\epsilon \leq \frac{1}{2}$, there is no suitable response.
}

\bx{
\ea{
	\item $\lim a_n = 0$. Take $n > 1$. Then 
	\begin{align*}
		\abs{\pbra{\pbra{\frac{1}{n}}}} &\leq 0 \\
		&< \epsilon.
	\end{align*}
	\item $\lim a_n = 0$. Take $n > 10$. Then 
	\begin{align*}
		\abs{\pbra{\pbra{\frac{10+n}{2n}}}} &= \abs{\pbra{\pbra{\frac{5}{n} + \frac{1}{2}}}} \\
		&\leq 0 \\
		&< \epsilon.
	\end{align*}
}

Usually, the sequence converges to some value by getting closer and closer eventually. Sometimes, the sequence converges to the exact value very fast, which means for some $n$, we don't need to choose a larger $n$. E.g. if we had the sequence of all 0s, we can choose any $n$ and claim the sequence converges to 0.
}

\bx{
\ea{
	\item Larger
	\item Larger
}
}

\bx{
\ea{
	\item We say a sequence $x_n$ \textit{converges} to $\infty$ if for every $\epsilon > 0$, $\exists N \in \mathbb{N}$ such that whenever $n \geq N$ we have that $\abs{x_n} > \epsilon$
	\item With our definition, we say this sequence diverges, but does not converge to $\infty$.
}
}

\bx{
\ea{
	\item Frequently.
	\item Eventually is stronger, and implies frequently.
	\item We say that a sequence $x_n$ converges to $x$ if it eventually is in a neighborhood of radius $\epsilon$ of $x$ for all $\epsilon > 0$.
	\item $x_n$ is only necessarily frequently in $(1.9, 2.1)$.
}
}

%% 2.3 %%
\setcounter{subsection}{3}
\setcounter{exercise}{0}

\bx{
Let $\epsilon > 0$. Consider $n \geq 1$, then 
\begin{equation*}
	\abs{a - a} = 0 < \epsilon.
\end{equation*}
}

\bx{
\ea{
	\item  We are given \((x_n) \rightarrow 0\), so we can make \(|x_n - 0|\) as small as we want. In particular, we choose N such that \(|x_n| < \epsilon|\sqrt{x_n}|\), whenever \(n \geq N\). To see that this N indeed works, observe that for all \(n \geq N\), 
\begin{equation*}
    |\sqrt{x_n}| = \frac{|x_n|}{|\sqrt{x_n}|} < \frac{1}{|\sqrt{x_n}|}\epsilon|\sqrt{x_n}| = \epsilon
\end{equation*}
so \((\sqrt{x_n}) \rightarrow 0\).

	\item We are given \((x_n) \rightarrow x\), so we can make \(|x_n - x|\) as small as we want. We choose N such that \begin{equation*}
    |x_n - x| < \epsilon|\sqrt{x_n} + \sqrt{x}| 
\end{equation*}
whenever \(n \geq N\). To see that this N works, notice that for all \(n \geq N\), \begin{equation*}
    |\sqrt{x_n} - \sqrt{x}| = \frac{|x_n - x|}{|\sqrt{x_n} + \sqrt{x}|} < \frac{1}{|\sqrt{x_n} + \sqrt{x}|}\epsilon|\sqrt{x_n} + \sqrt{x}| = \epsilon
\end{equation*} 
Therefore, \((\sqrt{x_n}) \rightarrow \sqrt{x}\).
}
}

\bx{
By the Order Limit Theorem, since 
\begin{align*}
	\forall n, x_n \leq y_n \Rightarrow \lim_{n\to\infty} y_n \geq \lim_{n\to\infty} x_n = l \\
	\forall n, z_n \leq y_n \Rightarrow \lim_{n\to\infty} y_n \leq \lim_{n\to\infty} z_n = l
\end{align*}
so $l \leq \lim_{n\to\infty} y_n \leq l \Rightarrow \lim_{n\to\infty} y_n = 1$.
}

\bx{
AFSOC $\lim a_n = l_1$ and $l_2$, for $l_1 \neq l_2$. Then we have that $\forall \epsilon > 0$, for sufficiently large $n$, that
\begin{align*}
	\abs{a_n - l_1} < \epsilon \\
	\abs{a_n - l_2} < \epsilon
\end{align*}
But this is a contradiction, since if we let $d = \abs{l_1 - l_2}$, and $\epsilon = \frac{d}{2}$, then 
\begin{align*}
	\abs{l_2 - l_1} \leq \abs{a_n - l_1} + \abs{-(a_n - l_2)} < 2 \epsilon \\
	d \leq \abs{a_n - l_1} + \abs{-(a_n - l_2)} < d,
\end{align*}
which leads to $d < d$. Thus, we must conclude that $l_1 = l_2$, and limits are unique.
}

\bx{
($Rightarrow$) If $(z_n)$ is convergent to some $l$, then $\forall \epsilon >0$, we have that $\exists N \in \mathbb{N}$ such that for $n \geq N$, that 
\begin{equation}
	\abs{z_n - l} < \epsilon \lra \abs{x_n - l} < \epsilon,  \abs{y_n - l} < \epsilon,
\end{equation}
because $z_n$ appears before or at the same time as $x_n$ and $y_n$ in the sequence.

($\Leftarrow$) If $(x_n), (y_n)$ are both convergent to some limit $l$, then we have for some $n\geq N \in \mathbb{N}$, that 
\begin{align*}
	\abs{x_n - l} &< \epsilon \\
	\abs{y_n - l} &< \epsilon.
\end{align*}
Then choose $n' \geq 2N$, then we have two cases, 
\begin{itemize}
	\item If $n'$ odd, then $z_{n'} = x_{(n'+1)/2}$. Since $\frac{n'+1}{2} \geq N$, $\abs{x_{(n'+1)/2} - l} < \epsilon$.
	\item If $n'$ even, then $z_{n'} = y_{n'/2}$. Since $\frac{n'}{2} \geq N$, $\abs{y_{n'/2} - l} < \epsilon$.
\end{itemize}
In both cases we have that for every $\epsilon > 0$, we can find $n' \geq N' = 2N \in \mathbb{N}$ such that 
\begin{equation}
	\abs{z_{n'} - l} < \epsilon,
\end{equation}
so $(z_n)$ is also convergent to $l$.
}

\bx{
\ea{
	\item By triangle inequality, we have $\abs{\abs{b_n} - \abs{b}} \leq \abs{b_n - b} < \epsilon$
	\item The converse is not true. Consider the sequence $a_n = (-1)^n$.
}
}

\bx{
\ea{
	\item Since $(a_n)$ is bounded, call $M$ the upper bound of $(a_n)$. Then since $\abs{b_n}$ can get arbitrarily small, we choose $n \geq N$ such that $\abs{b_n} < \frac{\epsilon}{M}$. Then we have
\begin{align*}
	\abs{a_nb_n} &\leq \abs{a_n}\abs{b_n} \\
	&< M \frac{\epsilon}{M} \\
	&< \epsilon.
\end{align*}

	We cannot use the Algebraic Limit Theorem because we are not given that $(a_n)$ necessarily converges.
 	\item No. For example, take $a_n = (-1)^n$, $b_n = 3$.
	\item When $a=0$, we have 
	\begin{equation*}
		\abs{a_nb_n - ab} \leq \abs{b_n}\abs{a_n - a}.
	\end{equation*}
	We can bound $\abs{b_n} \leq M$, and then choose $n$ such that $\abs{a_n - a} < \frac{\epsilon}{M}$. Then, 
	\begin{align*}
	\abs{a_nb_n - ab} &< M\frac{\epsilon}{M} \\
	&< \epsilon.
	\end{align*}
}
}

\bx{
\ea{
	\item $x_n = (-1)^n, y_n = (-1)^{n-1}$
	\item Impossible by theorem ???
	\item $b_n = \frac{1}{n}$
	\item Impossible by theorem ???
	\item $a_n = 0, b_n = n$
}
}

\bx{ 
No. Consider $a_n = \frac{1}{n}, a_n > 0$. $\lim a_n = 0$, but $0 \not> 0$.
}

\bx{
Since $\abs{a_n}$ gets arbitrarily small, we know for $n \geq N$, 
\begin{equation}
\abs{b_n - b} \leq \abs{a_n} < \epsilon.
\end{equation}
}

\bx{
Let $\lim x_n = x$. Then, for some $n_\epsilon \geq N$, we have $\abs{x_n - x} < \epsilon/2$. Now,
\begin{align*}
	\abs{y_n - x} &= \frac{1}{n}\pbra{\abs{\sum_{i=1}^{n_\epsilon}(x_i - x)} + \abs{\sum_{i=n_\epsilon}^n (x_i - x)}} \\
	&= \frac{n_\epsilon}{n}\underset{i\in[1,n_\epsilon]}{\max}(x_i - x) + \frac{n-n_\epsilon}{n}\underset{i\in[n_\epsilon, n]}{\max}(x_i - x) \\
	&= \frac{n_\epsilon}{n}\underset{i\in[1,n_\epsilon]}{\max}(x_i - x) + \frac{\epsilon}{2}
\end{align*}
now if we choose $n > \frac{n_\epsilon \underset{i\in[1,n_\epsilon]}{\max}(x_i - x)}{\epsilon/2}$, then we can bound the RHS by $\epsilon$.

Consider when $x_n = (-1)^n$. $(x_n)$ does not converge but $(y_n)$ does.
}

\bx{
\ea{
	\item Intuitively, the limit should go to 1, since we have $\frac{\infty}{\infty}$. 
	\begin{align*}
		&\lim_{n\to\infty} \lim_{m\to\infty} a_{m,n} = 1 \\
		&\lim_{m\to\infty} \lim_{n\to\infty} a_{m,n} = 0 \\
	\end{align*}
	\item A sequence $(a_{m,n})$ converges to $l$ if for every $\epsilon > 0$, $\exists N \in \mathbb{N}$ such that whenever $n\geq N$, we have that 
	\begin{align*}
		\abs{\lim_{n\to\infty} \lim_{m\to\infty} a_{m,n} - l} &< \epsilon \\
		\abs{\lim_{m\to\infty} \lim_{n\to\infty} a_{m,n} - l} &< \epsilon.
	\end{align*}
	i.e. we approach the same limit no matter what permutation of the index variables we iterate through.
}
}

%% 2.4 %%
\setcounter{subsection}{4}
\setcounter{exercise}{0}

\bx{
Suppose $\sum_{n=0}^\infty 2^nb_{2^n}$ diverges. Then consider
\begin{align*}
	s_{2^{k+1} - 1} &= b_1 + (b_2+b_3) + \dots \\
	&\geq b_2 + (b_4+b_4) + \dots \\
	&= (t_{k} - b_1)/2
\end{align*}
}

\bx{ 
\ea{
	\item We can show by induction that the sequence is decreasing. Thus, because the sequence starts at 3, we know it is bounded above by 1 and below by 0. Thus, the sequence converges.
	\item If $\lim x_n$ exists, then  $\lim x_{n+1}$ must be the same limit, because if the limit is a different value or doesn't exist, then $(x_n)$ does not converge.
	\item Suppose $\lim x_n = \lim x_{n+1} = x$. Then 
	\begin{align*}
		x &= \frac{1}{4-x} \\
		x^2 -4x + 1 &= 0 \\
		\lra x &= 2 - \sqrt{3}
	\end{align*}
}
}

\bx{
	We can use induction to show that $(y_n)$ is increasing. Since the sequence is increasing and starts at 1, we know that $(y_n)$ is bounded above by 4 and below by 0. Thus, by the Monotone Convergence Theorem, we conclude that $(y_n)$ converges. Now, we find the limit of the recurrence by taking the limits of both sides of the equation,
	\begin{align*}
		y &= 4 - \frac{1}{y} \\
		y^2 - 4y + 1 &= 0 \\
		y &= 2 + \sqrt{3}
	\end{align*}
}

\bx{
We can define the recurrence of this sequence as 
\begin{equation}
	a_{n+1} = \sqrt{2 a_{n}}.
\end{equation}
We can prove by induction that this sequence is increasing. We can also bound the sequence since ???.

Taking the limits of both sides,
\begin{align*}
	a &= \sqrt{2a} \\
	a^2 - 2a &= 0\\
	a &= 2 \tag{from i.c. $a_0 = 1$}.
\end{align*}
}

\bx{
\ea{
	\item By induction, we have
	
	\textbf{Base Case}: $x_1 = 2 \lra x_1^2 = 4 \geq 2$.
	
	\textbf{Inductive Hypothesis}: Given that for some $x_n, x_n^2 \geq 2$.
	
	\textbf{Inductive Step}: Consider
	\begin{align*}
		x_{n+1}^2 &= \frac{1}{4}\pa{x_n^2 + 4 + \frac{4}{x_n^2}} \\
		&\geq 1 + 1 = 2.
	\end{align*}
	
	Now consider
	\begin{align*}
		x_n - x_{n+1} &= x_n - \frac{1}{2}\pa{x_n + \frac{2}{x_n}} \\
		&= \frac{\frac{1}{2}x_n^2-1}{x_n} \\
		&\geq 0.
	\end{align*}
	Thus by the Monotone Convergence Theorem we know that $(x_n)$ converges. We now take limits of $x$ on both sides of the recurrence, yielding,
	\begin{align*}
		x &= \frac{1}{2}\pa{x + \frac{2}{x}} \\
		\frac{1}{2}x - \frac{1}{x} &= 0 \\
		x^2 - 2 &= 0 \\
		\lra x &= \sqrt{2}.
	\end{align*}
	\item We can modify the sequence to converge to $\sqrt{c}, c\geq 0$ by setting $x_1 = c$, and
	\begin{equation}
		x_{n+1} = \frac{1}{c}\pa{(c-1)x_n + \frac{c}{x_n}}
	\end{equation}
}
}

\bx{
\ea{
	\item Since we know that $(a_n)$ is bounded, it must also be the case that $\sup (a_n)$ is bounded. Then, $\sup\{a_k\}$ is a decreasing sequence, so by the Monotone Convergence Theorem, we know that $(y_n)$ converges.
	\item We can define 
	\begin{align}
		\lim \inf a_n &= \lim z_n, \text{ where } \\
		\lim z_n &= \inf\{a_k\,:\,k\geq n\}.
	\end{align}
	Since $\inf\{a_k\}$ is a increasing sequence, and $(a_n)$ is bounded, we know it converges.
	\item ???? x(
	An example when the inequality is strict is 
	\begin{equation}
		a_n = 0
	\end{equation}
	
	\item ($Rightarrow$) Suppose 
	\begin{equation}
		\lim \inf a_n = \lim \sup a_n,
	\end{equation}
	then 
}
}

%% 2.5 %%
\setcounter{subsection}{5}
\setcounter{exercise}{0}

\bx{
Suppose we have a convergent sequence. Then given any $\epsilon$, we can always find for $n \geq N \in \mathbb{N}$ that $\abs{a_n - l} < \epsilon$. For any subsequence of $(a_n)$, $a'_m = a_n$ will be such that $m\geq n$, so we can choose $m \geq N$ from earlier and conclude that $\abs{a'_m - l} < \epsilon$.
}

\bx{
\ea{
	\item Define 
\begin{align}
	s_i &= \sum_{j=1}^{i} a_j  \\
	b_i &= \sum_{k=1}^{i} a_{n_k},
\end{align}
where the series regrouping $a_i$ is divided into groups of $n_1, n_2, \dots$. Then $b_i$ is a subsequence of $s_n$, which means they converge to the same limit, namely $L$ in this case.
	\item Our proof does not apply to that example because that series did not converge in the first place.
}
}

\bx{
\ea{
	\item Consider
	\begin{equation}
		a_n = \begin{cases}
			\sum_{i=1}^n \frac{1}{2^i}, &n \text{ odd } \\
			\frac{1}{2^i}	, &n \text{ even}
		\end{cases}
	\end{equation}
	Then we have that $b_n = a_{2n-1}$ converges to 1 and $c_n = a_{2n}$ converges to 0.
	\item A monotone sequence that diverges means that sequence is not bounded. Thus, every subsequence will also be unbounded and thus impossible to be convergent.
	\item Consider the sequence
	\begin{equation}
		\{1, 1, \frac{1}{2}, 1, \frac{1}{2}, \frac{1}{3}, 1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4}, \dots\}
	\end{equation}
	\item Consider
	\begin{equation}
		a_n = \begin{cases}
			2^i, &n \text{ odd } \\
			\frac{1}{2^i}	, &n \text{ even}
		\end{cases}
		\label{eq:convdiv}
	\end{equation}
	\item By Bolzano-Weierstrass, since we have a subsequence that is bounded, we know we can find a convergent subsequence within this subsequence that converges.
}
}

\bx{
	AFSOC $(a_n)$ converges to $b \neq a$. Then we have that $\abs{a_n - b}$ can be arbitrarily small. But this implies that every subsequence will also converge to $b$, which is a contradiction.
	
	AFSOC $(a_n)$ does not converge. Then since $(a_n)$ is bounded, and every convergent subsequence converges to ??? i give up :(
}

\bx{
Consider $\abs{b^n}$. Since $\abs{b}<1$, we have that $\abs{b^n}$ is a decreasing sequence that is bounded below by 0, so we have
\begin{equation*}
	\abs{b} > l \geq 0.
\end{equation*}
We notice that $\abs{b^{2n}}$ is a subsequence that also converges to $L$, and since $\abs{b^{2n}} = \abs{b}^2$, by the Algebraic Limit Theorem, we have that $\abs{b^{2n}} \rightarrow l^2 = l \lra l = 0$. Since $\abs{b^n} \rightarrow 0$, we conclude $b^n \rightarrow 0$.
}

\bx{
We have $s = \sup S$, which means for any $\epsilon > 0$,
\begin{align*}
	&s - \epsilon < x \in S < a'_n \\
	\lra &\epsilon > \abs{s - a'_n} = \abs{a'_n - s}
\end{align*}
where $a'_n$ is a subsequence containing part of the infinite $a_n > x \in S$.
}

%% 2.6 %%
\setcounter{subsection}{6}
\setcounter{exercise}{0}

\bx{
\ea{
	\item $a_n = 1 + \pa{-\frac{1}{2}}^n$
	\item $a_n = n$
	\item Impossible, since a Cauchy sequence implies convergence, which means every subsequence will also converge.
	\item You can use Equation  (\ref{eq:convdiv}). Literally anything that diverges but has a convergent subsequence.
}
}

\bx{
If we have that $(x_n) \rightarrow x$, then we can make $\abs{x_n - x}$ arbitrarily small. Consider
\begin{align*}
	\abs{x_n - x_m} = \abs{x_n - x + x - x_m} \\
	&\leq \abs{x_n - x} + \abs{x_m - x} \tag{Triangle Inequality} \\
	&< \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon
\end{align*}
}

\bx{
\ea{
	\item The \textit{pseudo-Cauchy} definition is different because it only looks at consecutive terms
	\item Consider the harmonic series, where $s_{n+1} - s_{n} = \frac{1}{n}$.
}
}

\bx{
\begin{align*}
	\abs{c_{n+1} - c_n} &= \abs{\abs{a_{n+1} - b_{n+1}} - \abs{a_n - b_n}} \\
	&\leq \abs{a_{n+1} - a_n + b_{n+1} - b_n} \\
	&\leq \abs{a_{n+1} - a_n} + \abs{b_{n+1} - b_n} \\
	&< \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon.
\end{align*}
}

\bx{
\ea{
	\item Let $a_n = x_n + y_n$, then
	\begin{align*}
		\abs{a_{n+1} - a_n} &= \abs{x_{n+1} - x_n + y_{n+1} - y_n} \\
		&\leq \abs{x_{n+1} - x_n} + \abs{y_{n+1} - y_n} \\
		&< \epsilon
	\end{align*}
	\item 
}
}

\bx{
\ea{
	\item 
}
}

%% 2.7 %%
\setcounter{subsection}{7}
\setcounter{exercise}{0}

%% 2.8 %%
\setcounter{subsection}{8}
\setcounter{exercise}{0}

\bx{
\begin{align*}
	\lim s_{nn} &= \sum_{i=0}^{\infty} -\pa{\frac{1}{2}}^i \\
	&= -2.
\end{align*}
The value is equal to summing the columns first.
}

\bx{
By the Absolute Convergence test, since we know for fixed $i$ that $\sum_{j=1}^\infty \abs{a_{ij}}$ converges, then we know for fixed $i$ that each $\sum_{j=1}^\infty a_{ij}$ converges to some $c_i$ as well. 

Then, since 
\begin{align*}
	\sum_{j=1}^\infty \abs{a_{ij}} &\geq \sum_{j=1}^\infty a_{ij} \\
	\lra b_i \geq c_i,
\end{align*}
and we know that $\sum_{i=1}^\infty b_i$ converges, we conclude that $\sum_{i=1}^\infty c_i$ must converge as well, implying that 
\begin{equation}
	\sum_{i=1}^\infty \sum_{j=1}^\infty a_{ij}
\end{equation}
converges as well.
}

\bx{
\ea{
	\item Since $\sum_{i=1}^\infty \sum_{j=1}^\infty \abs{a_{ij}}$ converges, we know that we can find $m,n \geq N$ such that 
	\begin{equation*}
		\abs{t_{mn} - L} < 0.9,
	\end{equation*}
	and then choose our upper bound as 
	\begin{equation}
	M = \max \{l\} \cup \{a_{mn} \mid m,n < N\}
	\end{equation}
	Since $t_{nn}$ is an increasing sequence, and is bounded above, by the Monotone Convergence Theorem, $t_{nn}$ converges.
	\item Consider 
	\begin{align*}
		\abs{s_{n+1, n+1} - s_{nn}} &= \abs{a_{n+1, n+1}} \\
		&= \abs{t_{n+1, n+1} - t_{nn}} \\
		&< \epsilon.
	\end{align*}
	So $(s_{nn})$ is a Cauchy Sequence and converges.
}
}

\bx{
\ea{
	\item Since $(t_{nn})$ is an increasing sequence and is bounded above, we know there exists a $t_{n_0n_0}$ such that 
	\begin{equation}
	B - \frac{\epsilon}{2} < t_{n_0n_0} \leq B.
	\end{equation}
	For $N_1 = n_0$, since for $m,n \geq N_1$, $t_{mn} > t_{n_0n_0}$, and $t_{mn} \leq B$ (upper bound $B$), we will have that 
	\begin{equation}
	B - \frac{\epsilon}{2} < t_{m,n} \leq B.
	\end{equation}
	\item Since $(t_{nn}0$ converges, we can find $n \geq N$ such that
	\begin{align*}
	\abs{s_{nn} - S} &= \abs{s_{nn} - \sum_{i=1}^\infty \sum_{j=1}^\infty a_{ij}} \\
	&= \abs{\sum_{i=n+1}^\infty \sum_{j=n+1}^\infty a_{ij}} \\
	&<\abs{\sum_{i=n+1}^\infty \sum_{j=n+1}^\infty \abs{a_{ij}}} \\
	&= \abs{t_{nn} - \sum_{i=1}^\infty \sum_{j=1}^\infty \abs{a_{ij}}} \\
	&< \epsilon.
	\end{align*}
	So for $m,n \geq N$, 
	\begin{equation}
		\abs{s_{mn} - S} \leq 
	\end{equation}
	hm?????????/
}
}